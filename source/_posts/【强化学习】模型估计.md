---
title: 【强化学习】模型估计
date: 2017-11-06 15:49:47
tags:
    - RL
    - robotics
    - David Silver
categories: 【强化学习】
---

{% img [MBRL] http://on99gq8w5.bkt.clouddn.com/MBRL.png?imageMogr2/thumbnail/500x500 %}
<!--more-->
# 0 引言
如果不能对环境建立模型，包括状态转移和奖励函数，那么从很多经历中学习出一个模型，也是一件极好的事情。也就是做模型估计。

基于模型学习的优点：
* 监督学习
* 可以推理模型的不确定性
当然，也有缺点：
* 模型误差+值函数误差 -> 双重误差

模型究竟是一个什么鬼呢？
模型就是一个使用参数$\eta$描述的$MDP\langle \mathcal{S},\mathcal{A},\mathcal{P},\mathcal{R} \rangle$,假设状态空间和动作空间已知。那么一个模型就是状态转移和奖励函数。即$\mathcal{M}=\langle \mathcal{P}_{\eta},\mathcal{R}_{\eta} \rangle$.
$$
S_{t+1}\sim \mathcal{P}_{\eta}(S_{t+1}|S_t,A_t) \
R_{t+1}\sim \mathcal{R}_{\eta}(R_{t+1}|S_t,A_t) 
$$
通常假设状态转移和奖励函数条件独立，即
$$
\mathbb{P}[S_{t+1},R_{t+1}|S_t,A_t]=\mathbb{P}[S_{t+1}|S_t,A_t]\mathbb{P}[R_{t+1}|S_t,A_t]
$$

经典的算法有Dyna-Q和iLOG

# 1 模型估计


# 2 经典算法
## 2.1 Dyna-Q
Dyna-Q算法的伪代码如下：
{% img [Dyna] http://on99gq8w5.bkt.clouddn.com/Dyna.png?imageMogr2/thumbnail/500x500 %}

## 2.2 iLOG


# 3 基于模型的搜索
## 3.1 蒙特卡罗搜索


## 3.2 TD搜索

# 4 后续发展
关于

# 参考文献
[1] David Silver, reinforcement learning lecture 8